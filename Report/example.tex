\documentclass[oneside]{article}
\usepackage{fullpage}
\usepackage[pdftex]{graphicx}
\DeclareGraphicsExtensions{.png,.pdf}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{float}
\renewcommand\rmdefault{bch}
\usepackage[small]{caption}
\usepackage[small]{titlesec}
\linespread{1.07} 

\title{Programming Assignment 6}
\author{Matt Delhey}
\date{\today}

\raggedbottom

\begin{document}
\maketitle 

\section{K-means Clustering}
K-means is an iterative algorithm with two primary steps. Given a set
of $K$ centroids, the first step is to calculate the distance from
each centroid to each observation in the data matrix $X$. In this case
we use the second norm squared $||x^{(i)} - \mu_j||^2$. The second
step is to assign each $x^{(i)}$ to its closest cluster, i.e. the
cluster that is the minimum distance from the point. We repeat this
process for an arbitrary number of iterations.

In practice, we won't to run this algorithm multiple times with random
initialization in order to ensure that our clusters are not the result
of a bad initialization.

\subsection{K-means on example dataset}
\begin{figure}[hbtp]
  \centering
  \includegraphics[width = 0.75\linewidth]{p1}
  \caption{Output of k-means over several iterations.}
  \label{fig:one}
\end{figure}

Figure \ref{fig:one} shows the result of running k-means on the
example dataset for multiple iterations (under a single
initialization). Because the problem is in two dimensions, we can
actually plot and see how each iteration improves the positioning of
the clusters.

\subsection{K-means for image compression}
\begin{figure}[hbtp]
  \centering
  \includegraphics[width = 0.75\linewidth]{p2}
  \caption{Original and reconstructed image (when using k-means to
    compress the image).}
  \label{fig:two}
\end{figure}

We can use the k-means algorithm to compress images by selecting $K$
colors to represent the image instead of the traditional $24$ bit
representation. Using a K-means to cluster the colors, we can reduce
the original image size by about a factor of $6$. Figure \ref{fig:two}
shows the results of using K-means for image compression. On the left
is the uncompressed, original image. On the right is the
compressed. As we can see, K-means does a reasonably good job at
approximating the original image. On the other hand the original image
is clearly a better representation of the image. The K-means
representation would most likely be sufficient for machine learning
problems.

\section{Principal Components Analysis}

\subsection{PCA on example dataset}
In this example, we use PCA to reduce a two-dimensional dataset into a
one-dimensional dataset. By doing so, we are able to visualize the
results in both the original and reduced dimension, as seen in Figure
\ref{fig:three}. We also have to keep in mind that PCA is sensitive to
normalization of the dataset. The first principle component of the
dataset, seen in Figure \ref{fig:four}, represents the best linear
explanation for the variance of the observed data.

\begin{figure}[hbtp]
  \centering
  \includegraphics[width = 0.45\linewidth]{p3}
  \includegraphics[width = 0.45\linewidth]{p4}
  \caption{(Left) Example dataset for PCA. (Right) Computed
    eigenvectors of the example dataset.}
  \label{fig:three}
\end{figure}

\begin{figure}[hbtp]
  \centering
  \includegraphics[width = 0.65\linewidth]{p5}
  \caption{The normalized and projected data after PCA.}
  \label{fig:four}
\end{figure}

\subsection{PCA for faces dataset}
In this example, we use PCA to reduce the dimension of a dataset
consisting of images of faces. Each row in the original data matrix
$X$ represents a $32 x 32$ image. We can use principle components to
reduce the dimensionality of the dataset and remove correlated
predictors. In Figure \ref{fig:five}, we can see the original faces
dataset compared to its first $36$ principle components. The first few
PC's seem to extract much of the general features in the faces but
perhaps not enough to get a great testing error. When we instead use
the first $100$ principle components, we get a much better
representation of the original images while still reducing our vector
size by an order of magnitude, as seen in \ref{fig:six}. This would be
a good compromise between richness of features and speediness of
computation.

\begin{figure}[hbtp]
  \centering
  \includegraphics[width = 0.45\linewidth]{p6}
  \includegraphics[width = 0.45\linewidth]{p7}
  \caption{(Left) The original faces dataset $d = 1024$. (Right) The
    first $36$ principle components of the faces dataset.}
  \label{fig:five}
\end{figure}

\begin{figure}[hbtp]
  \centering
  \includegraphics[width = .95\linewidth]{p8}
  \caption{Original and reconstructed face dataset. The recovered
    faces are reconstructed from only the top $100$ principal
    components, versus a $1024$ size vector for the original dataset.}
  \label{fig:six}
\end{figure}

\end{document}